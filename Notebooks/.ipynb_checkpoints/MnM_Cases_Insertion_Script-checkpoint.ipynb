{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21857e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pydicom\n",
    "from pydicom.dataset import Dataset\n",
    "import pydicom._storage_sopclass_uids\n",
    "from bson.objectid import ObjectId\n",
    "import copy\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import nibabel as nib\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "from catchConverter import catchConverter\n",
    "\n",
    "from RoomOfRequirement.Quad import *\n",
    "from RoomOfRequirement.Annotation import *\n",
    "from RoomOfRequirement.ImageOrganizer import *\n",
    "from RoomOfRequirement.Evaluation import *\n",
    "from RoomOfRequirement.Case import *\n",
    "from RoomOfRequirement.utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from datetime import date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2784e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad = QUAD_Manager()\n",
    "quad._drop_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50aee26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad = QUAD_Manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce01922",
   "metadata": {},
   "source": [
    "## Make Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d51ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Owner:  {'_id': ObjectId('64be56fc0a9e385681abace4'), 'firstname': 'Thomas', 'lastname': 'Hadler', 'birthdate': '1991-06-20', 'gender': 'M', 'projectowner': True}\n",
      "Cohort: {'_id': ObjectId('64be56fc0a9e385681abace5'), 'name': 'MnM2', 'owner': ObjectId('64be56fc0a9e385681abace4'), 'ownername': 'Thomas | Hadler | 1991-06-20 | M', 'studyuids': []}\n"
     ]
    }
   ],
   "source": [
    "owner = {'firstname': 'Thomas', 'lastname': 'Hadler', 'birthdate': str(date(day=20,month=6,year=1991)), \n",
    "         'gender':'M', 'projectowner':True}\n",
    "quad.pers_coll.insert_one(owner)\n",
    "owner = quad.pers_coll.find_one(owner)\n",
    "print('Owner: ', owner)\n",
    "\n",
    "cohort = dict()\n",
    "cohort['name']      = 'MnM2'\n",
    "cohort['owner']     = owner['_id']\n",
    "cohort['ownername'] = owner['firstname']+' | '+owner['lastname']+' | '+owner['birthdate']+' | '+owner['gender']\n",
    "cohort['studyuids'] = []\n",
    "try: quad.coho_coll.insert_one(cohort)\n",
    "except Exception as e: print(e)\n",
    "cohort = quad.coho_coll.find_one({'name': 'MnM2'})\n",
    "print('Cohort:', cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffcba63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613a9b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path  = '/Users/thomas/Desktop/CMR/LazyLuna_Data/Data/MnM2/dataset'\n",
    "csv_path   = '/Users/thomas/Desktop/CMR/LazyLuna_Data/Data/MnM2/dataset_information.csv'\n",
    "store_path = '/Users/thomas/Desktop/mnmout'\n",
    "\n",
    "fpaths = sorted([os.path.join(base_path, fp) for fp in os.listdir(base_path) if fp!='.DS_Store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33643e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed1a213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2736792b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 196, 13, 25)\n"
     ]
    }
   ],
   "source": [
    "def get_data(path, name='SA_CINE'):\n",
    "    filenames = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "    niis = [nib.load(fname) for fname in filenames if name in fname]\n",
    "    return niis[0]\n",
    "\n",
    "def get_imgs_and_masks(path):\n",
    "    sa_all   = get_data(path, 'SA_CINE')  .get_fdata()\n",
    "    sa_es    = get_data(path, 'SA_ES.nii').get_fdata()\n",
    "    sa_es_gt = get_data(path, 'SA_ES_gt') .get_fdata()\n",
    "    sa_ed    = get_data(path, 'SA_ED.nii').get_fdata()\n",
    "    sa_ed_gt = get_data(path, 'SA_ED_gt') .get_fdata()\n",
    "    la_all   = get_data(path, 'LA_CINE')  .get_fdata()\n",
    "    la_es    = get_data(path, 'LA_ES.nii').get_fdata()\n",
    "    la_es_gt = get_data(path, 'LA_ES_gt') .get_fdata()\n",
    "    la_ed    = get_data(path, 'LA_ED.nii').get_fdata()\n",
    "    la_ed_gt = get_data(path, 'LA_ED_gt') .get_fdata()\n",
    "    return sa_all, sa_es, sa_es_gt, sa_ed, sa_ed_gt, la_all, la_es, la_es_gt, la_ed, la_ed_gt\n",
    "\n",
    "def get_imgs_and_masks_in_nifti(path):\n",
    "    sa_all   = get_data(path, 'SA_CINE')\n",
    "    sa_es    = get_data(path, 'SA_ES.nii')\n",
    "    sa_es_gt = get_data(path, 'SA_ES_gt')\n",
    "    sa_ed    = get_data(path, 'SA_ED.nii')\n",
    "    sa_ed_gt = get_data(path, 'SA_ED_gt')\n",
    "    la_all   = get_data(path, 'LA_CINE')\n",
    "    la_es    = get_data(path, 'LA_ES.nii')\n",
    "    la_es_gt = get_data(path, 'LA_ES_gt')\n",
    "    la_ed    = get_data(path, 'LA_ED.nii')\n",
    "    la_ed_gt = get_data(path, 'LA_ED_gt')\n",
    "    return sa_all, sa_es, sa_es_gt, sa_ed, sa_ed_gt, la_all, la_es, la_es_gt, la_ed, la_ed_gt\n",
    "\n",
    "def get_sax_stack_with_mask_stack_and_lax_stack_with_mask_stack(path):\n",
    "    sa_all, sa_es, sa_es_gt, sa_ed, sa_ed_gt, la_all, la_es, la_es_gt, la_ed, la_ed_gt = get_imgs_and_masks(path)\n",
    "    # get es-/ed-phase, for SA and LA\n",
    "    print(sa_all.shape)\n",
    "    \n",
    "#get_imgs_and_masks(fpaths[233])\n",
    "get_sax_stack_with_mask_stack_and_lax_stack_with_mask_stack(fpaths[233])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4638d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_stack_to_dicom(nii_imgs, studyuid, patientname, series_descr):\n",
    "    depthandtime2sop = dict()         # (d,t) to sop\n",
    "    sop2dicoms = dict()               # sop to dcm\n",
    "    ph, pw, pdepth = nii_imgs.header['pixdim'][1:4]\n",
    "    h, w, nr_slices  = nii_imgs.header['dim'][1:4]\n",
    "    \n",
    "    folder = os.path.join(store_path, 'Imgs')\n",
    "    if not os.path.exists(folder): \n",
    "        os.makedirs(folder)\n",
    "    folder = os.path.join(store_path, 'Imgs', patientname)\n",
    "    if not os.path.exists(folder): \n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    imgs = nii_imgs.get_fdata()\n",
    "    for p in range(imgs.shape[-1]):\n",
    "        seriesinstanceuid = pydicom.uid.generate_uid()\n",
    "        for d in range(imgs.shape[-2]):\n",
    "            img = imgs[:,:,d, p]\n",
    "            img = img.astype(np.uint16)\n",
    "            meta = pydicom.Dataset()\n",
    "            meta.MediaStorageSOPClassUID = pydicom._storage_sopclass_uids.MRImageStorage\n",
    "            meta.MediaStorageSOPInstanceUID = pydicom.uid.generate_uid()\n",
    "            meta.TransferSyntaxUID = pydicom.uid.ExplicitVRLittleEndian\n",
    "            ds = Dataset()\n",
    "            ds.file_meta = meta\n",
    "            ds.SOPInstanceUID = pydicom.uid.generate_uid()\n",
    "            ds.is_little_endian = True\n",
    "            ds.is_implicit_VR = False\n",
    "            ds.SOPClassUID = pydicom._storage_sopclass_uids.MRImageStorage\n",
    "            ds.PatientName = patientname\n",
    "            ds.PatientID = \"123456\"\n",
    "            ds.Modality = \"MR\"\n",
    "            ds.SeriesInstanceUID = seriesinstanceuid\n",
    "            ds.StudyInstanceUID  = studyuid\n",
    "            ds.FrameOfReferenceUID = pydicom.uid.generate_uid()\n",
    "            ds.SeriesDescription = series_descr\n",
    "            ds.SliceLocation     = d * pdepth\n",
    "            ds.SliceThickness    = str(pdepth)\n",
    "            ds.SpacingBetweenSlices = str(pdepth)\n",
    "            ds.PixelSpacing = str(ph)+'\\\\'+str(pw)\n",
    "            ds.SeriesNumber = 0\n",
    "            ds.BitsStored = 16\n",
    "            ds.BitsAllocated = 16\n",
    "            ds.SamplesPerPixel = 1\n",
    "            ds.HighBit = 15\n",
    "            ds.ImagesInAcquisition = \"1\"\n",
    "            ds.Rows    = h\n",
    "            ds.Columns = w\n",
    "            ds.InstanceNumber = p\n",
    "            ds.ImagePositionPatient = r\"0\\0\\1\"\n",
    "            ds.ImageOrientationPatient = r\"1\\0\\0\\0\\-1\\0\"\n",
    "            ds.ImageType = r\"ORIGINAL\\PRIMARY\\AXIAL\"\n",
    "            ds.RescaleIntercept = \"0\"\n",
    "            ds.RescaleSlope     = \"1\"\n",
    "            ds.PhotometricInterpretation = \"MONOCHROME2\"\n",
    "            ds.PixelRepresentation = 1\n",
    "            pydicom.dataset.validate_file_meta(ds.file_meta, enforce_standard=True)\n",
    "            ds.PixelData = img.tobytes()\n",
    "            ds.private_block(0x000b, 'Lazy Luna: '+series_descr,     create=True)\n",
    "            #filename = os.path.join(bpath, casename, str(d)+'.dcm')\n",
    "            \n",
    "            folder = os.path.join(store_path, 'Imgs', patientname)\n",
    "            if not os.path.exists(folder): os.mkdir(folder)\n",
    "            filename = os.path.join(folder, series_descr+'_phase_'+str(p)+'_slice_'+str(d)+'.dcm')\n",
    "            ds.save_as(filename=filename, write_like_original=False)\n",
    "            \n",
    "            depthandtime2sop[(d,p)] = ds.SOPInstanceUID\n",
    "            sop2dicoms[ds.SOPInstanceUID] = ds\n",
    "    return depthandtime2sop, sop2dicoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9074b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_anno_dict(mask, img_size, pixel_size, series_descr):\n",
    "    endo_cont = to_polygon((mask==1).astype(np.int16))\n",
    "    myo_cont  = to_polygon((mask==2).astype(np.int16))\n",
    "    rv_cont   = to_polygon((mask==3).astype(np.int16))\n",
    "    anno_dict = dict()\n",
    "    if series_descr=='SAX CINE':\n",
    "        if not endo_cont.is_empty: anno_dict['lv_endo']  = {'cont': endo_cont}\n",
    "        if not myo_cont.is_empty : anno_dict['lv_myo']   = {'cont': myo_cont}\n",
    "        if not rv_cont.is_empty:   anno_dict['rv_endo']  = {'cont': rv_cont}\n",
    "    if series_descr=='LAX CINE 4CV':\n",
    "        if not endo_cont.is_empty: anno_dict['lv_lax_endo']  = {'cont': endo_cont}\n",
    "        if not myo_cont.is_empty : anno_dict['lv_lax_myo']   = {'cont': myo_cont}\n",
    "        if not rv_cont.is_empty:   anno_dict['rv_lax_endo']  = {'cont': rv_cont}\n",
    "    for c in anno_dict.keys():\n",
    "        anno_dict[c]['imageSize'] = list(map(int, img_size))\n",
    "        anno_dict[c]['pixelSize'] = list(map(int, pixel_size))\n",
    "        anno_dict[c]['subpixelResolution'] = 1\n",
    "    return anno_dict\n",
    "\n",
    "def save_json(storage_path, anno_dict):\n",
    "    def convertShapely(d):\n",
    "        for _i, i in d.items():\n",
    "            if 'cont' in i and not isinstance(i['cont'], list): i['cont'] = mapping(i['cont'])\n",
    "            elif isinstance(i, dict): convertShapely(i)\n",
    "    convertShapely(anno_dict)\n",
    "    with open(storage_path, 'w') as f: json.dump(anno_dict, f)\n",
    "\n",
    "def get_phases(path):\n",
    "    sa_all, sa_es, sa_es_gt, sa_ed, sa_ed_gt, la_all, la_es, la_es_gt, la_ed, la_ed_gt = get_imgs_and_masks(path)\n",
    "    es_sa_phase = [p for p in range(sa_all.shape[-1]) if np.array_equal(sa_all[:,:,0,p], sa_es[:,:,0])][0]\n",
    "    ed_sa_phase = [p for p in range(sa_all.shape[-1]) if np.array_equal(sa_all[:,:,0,p], sa_ed[:,:,0])][0]\n",
    "    es_la_phase = [p for p in range(la_all.shape[-1]) if np.array_equal(la_all[:,:,0,p], la_es[:,:,0])][0]\n",
    "    ed_la_phase = [p for p in range(la_all.shape[-1]) if np.array_equal(la_all[:,:,0,p], la_ed[:,:,0])][0]\n",
    "    return es_sa_phase, ed_sa_phase, es_la_phase, ed_la_phase\n",
    "\n",
    "\n",
    "def nii_stack_to_annodict(nii_masks, phase, studyuid, depthandtime2sop, series_descr):\n",
    "    ph, pw, pdepth  = nii_masks.header['pixdim'][1:4]\n",
    "    h, w, nr_slices = nii_masks.header['dim'][1:4]\n",
    "    nii_masks = nii_masks.get_fdata()\n",
    "    annos = dict()\n",
    "    for d in range(nii_masks.shape[-1]):\n",
    "        mask = nii_masks[:,:,d]\n",
    "        annos[depthandtime2sop[(d,phase)]] = mask_to_anno_dict(mask, (h,w), (ph,pw), series_descr)\n",
    "    return annos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "461c5c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 23 8 23\n",
      "[0. 1. 2. 3.]\n",
      "8 23 8 23\n",
      "[0. 1. 2. 3.]\n",
      "8 22 8 22\n",
      "[0. 1. 2. 3.]\n",
      "7 24 7 24\n",
      "[0. 1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "# Unpack all to folders\n",
    "\n",
    "studyuids = []\n",
    "for i_p, p in enumerate(fpaths):\n",
    "    #p = fpaths[230]\n",
    "    patientname = os.path.basename(p)\n",
    "    studyuid    = pydicom.uid.generate_uid()\n",
    "    studyuids.append(studyuid)\n",
    "\n",
    "    # get images and masks\n",
    "    sa_all, sa_es, sa_es_gt, sa_ed, sa_ed_gt, la_all, la_es, la_es_gt, la_ed, la_ed_gt = get_imgs_and_masks_in_nifti(p)\n",
    "\n",
    "    # transform images to dicoms\n",
    "    series_descr = 'SAX CINE'\n",
    "    sax_depthandtime2sop, sax_sop2dicoms = convert_stack_to_dicom(sa_all, studyuid, patientname, series_descr)\n",
    "    series_descr = 'LAX CINE 4CV'\n",
    "    lax_depthandtime2sop, lax_sop2dicoms = convert_stack_to_dicom(la_all, studyuid, patientname, series_descr)\n",
    "\n",
    "    # get relevant phases\n",
    "    es_sa_phase, ed_sa_phase, es_la_phase, ed_la_phase = get_phases(p)\n",
    "    print(es_sa_phase, ed_sa_phase, es_la_phase, ed_la_phase)\n",
    "\n",
    "    # transform masks to anno dictionaries\n",
    "    folder = os.path.join(store_path, 'Gold')\n",
    "    if not os.path.exists(folder): os.makedirs(folder)\n",
    "    folder = os.path.join(store_path, 'Gold', studyuid)\n",
    "    if not os.path.exists(folder): os.makedirs(folder)\n",
    "\n",
    "    sa_es_anno_dict = nii_stack_to_annodict(sa_es_gt, es_sa_phase, studyuid, sax_depthandtime2sop, 'SAX CINE')\n",
    "    sa_ed_anno_dict = nii_stack_to_annodict(sa_ed_gt, ed_sa_phase, studyuid, sax_depthandtime2sop, 'SAX CINE')\n",
    "    la_es_anno_dict = nii_stack_to_annodict(la_es_gt, es_la_phase, studyuid, lax_depthandtime2sop, 'LAX CINE 4CV')\n",
    "    la_ed_anno_dict = nii_stack_to_annodict(la_ed_gt, ed_la_phase, studyuid, lax_depthandtime2sop, 'LAX CINE 4CV')\n",
    "    print(np.unique(la_ed_gt.get_fdata()))\n",
    "\n",
    "    for sop in sa_es_anno_dict.keys(): save_json(os.path.join(folder, sop+'.json'), sa_es_anno_dict[sop])\n",
    "    for sop in sa_ed_anno_dict.keys(): save_json(os.path.join(folder, sop+'.json'), sa_ed_anno_dict[sop])\n",
    "    for sop in la_es_anno_dict.keys(): save_json(os.path.join(folder, sop+'.json'), la_es_anno_dict[sop])\n",
    "    for sop in la_ed_anno_dict.keys(): save_json(os.path.join(folder, sop+'.json'), la_ed_anno_dict[sop])\n",
    "    \n",
    "    if i_p==3: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b7593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be1f836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168816ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96e99711",
   "metadata": {},
   "source": [
    "## Make Readers and Task Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d142cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read excel file\n",
    "csv_path = '/Users/thomas/Desktop/CMR/LazyLuna_Data/Data/MnM2/dataset_information.csv'\n",
    "reader_lines = [r for r in csv.reader(open(csv_path,  newline='\\n'), delimiter=',', quotechar='\"',)]\n",
    "reader_header = reader_lines[0]\n",
    "reader_data = reader_lines[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17116736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NI': True, 'reader': True, 'firstname': 'Gold', 'lastname': 'per Site', 'birthdate': '0001-01-01', 'gender': 'Private'}\n",
      "{'_id': ObjectId('64be57010a9e385681abace6'), 'NI': True, 'reader': True, 'firstname': 'Gold', 'lastname': 'per Site', 'birthdate': '0001-01-01', 'gender': 'Private'}\n",
      "{'displayname': 'Gold', 'creation_date': '2023-07-24', 'software': 'CVI42', 'experience': 'More than 1000', 'profession': 'CMR Expert', 'reader_ids': [ObjectId('64be57010a9e385681abace6')], 'st_date': '2021-01-01', 'end_date': '2021-01-01', 'task_description': 'Together with clinical collaborators from six different hospitals in Spain, Canada and Germany, a public CMR dataset was established from 375 participants, scanned with four different scanners (Siemens, Philips, General Electric (GE) and Canon) and annotated using a consistent contouring SOP across centres. [...] Following the clinical protocol, short-axis views were annotated at the end-diastolic (ED) and end-systolic (ES) phases, as they correspond to the phases used to compute the relevant clinical biomarkers for cardiac diagnosis and follow-up. Three main regions were considered: the left and right ventricle (LV and RV, respectively) cavities and the left ventricle myocardium (MYO). In order to reduce the inter-observer and inter-centre variability in the contours, in particular at the apical and basal regions, a detailed revision of the provided segmentations was performed by four researchers in pairs. They applied the same SOP across all CMR datasets to obtain the final ground truth. To generate consistent annotations for the research community, we chose to apply the SOP that was already used by the ACDC challenge, as follows: a) The LV and RV cavities must be completely covered, including the papillary muscles. b) No interpolation of the MYO boundaries must be performed at the basal region. c) The RV must have a larger surface at the ED time-frame compared to ES. d) The RV does not include the pulmonary artery. Published in: \"Multi-Centre, Multi-Vendor and Multi-Disease Cardiac Segmentation: The M&Ms Challenge\"', 'reader_description': 'Every CMR study was annotated manually by an expert clinician from the centre of origin, with experiences ranging from 3 to more than 10 years.', 'studyuids': ['1.2.826.0.1.3680043.8.498.33660098538471445761153731305311549665', '1.2.826.0.1.3680043.8.498.19303731869540862052339687494868630356', '1.2.826.0.1.3680043.8.498.11942557282875056998733521273386420574', '1.2.826.0.1.3680043.8.498.67776364827458814494361500965925660581']}\n",
      "{'displayname': 'Gold', 'creation_date': '2023-07-24', 'software': 'CVI42', 'experience': 'More than 1000', 'profession': 'CMR Expert', 'reader_ids': [ObjectId('64be57010a9e385681abace6')], 'st_date': '2021-01-01', 'end_date': '2021-01-01', 'task_description': 'Together with clinical collaborators from six different hospitals in Spain, Canada and Germany, a public CMR dataset was established from 375 participants, scanned with four different scanners (Siemens, Philips, General Electric (GE) and Canon) and annotated using a consistent contouring SOP across centres. [...] Following the clinical protocol, short-axis views were annotated at the end-diastolic (ED) and end-systolic (ES) phases, as they correspond to the phases used to compute the relevant clinical biomarkers for cardiac diagnosis and follow-up. Three main regions were considered: the left and right ventricle (LV and RV, respectively) cavities and the left ventricle myocardium (MYO). In order to reduce the inter-observer and inter-centre variability in the contours, in particular at the apical and basal regions, a detailed revision of the provided segmentations was performed by four researchers in pairs. They applied the same SOP across all CMR datasets to obtain the final ground truth. To generate consistent annotations for the research community, we chose to apply the SOP that was already used by the ACDC challenge, as follows: a) The LV and RV cavities must be completely covered, including the papillary muscles. b) No interpolation of the MYO boundaries must be performed at the basal region. c) The RV must have a larger surface at the ED time-frame compared to ES. d) The RV does not include the pulmonary artery. Published in: \"Multi-Centre, Multi-Vendor and Multi-Disease Cardiac Segmentation: The M&Ms Challenge\"', 'reader_description': 'Every CMR study was annotated manually by an expert clinician from the centre of origin, with experiences ranging from 3 to more than 10 years.', 'studyuids': ['1.2.826.0.1.3680043.8.498.33660098538471445761153731305311549665', '1.2.826.0.1.3680043.8.498.19303731869540862052339687494868630356', '1.2.826.0.1.3680043.8.498.11942557282875056998733521273386420574', '1.2.826.0.1.3680043.8.498.67776364827458814494361500965925660581'], '_id': ObjectId('64be57010a9e385681abace7')}\n"
     ]
    }
   ],
   "source": [
    "# make reader\n",
    "fn, ln      = 'Gold', 'per Site'\n",
    "m,d,y       = 1, 1, 2021\n",
    "ausw_date   = date(day=int(d), month=int(m), year=int(y))\n",
    "bday_guess  = date(day=1, month=1, year=1)\n",
    "reader      = {'NI': True, 'reader': True, \n",
    "               'firstname': fn, 'lastname': ln, \n",
    "               'birthdate': str(bday_guess), \n",
    "               'gender': 'Private'}\n",
    "\n",
    "print(reader)\n",
    "try: quad.pers_coll.insert_one(reader)\n",
    "except Exception as e: print(e)\n",
    "reader = quad.pers_coll.find_one({'firstname': fn, 'lastname': ln})\n",
    "print(reader)\n",
    "\n",
    "# make task environment\n",
    "task_env   = {'displayname':   'Gold', \n",
    "              'creation_date': str(date.today()), \n",
    "              'software':      'CVI42', \n",
    "              'experience':    'More than 1000',\n",
    "              'profession':    'CMR Expert',\n",
    "              'reader_ids':    [reader['_id']], \n",
    "              'st_date':       str(ausw_date), \n",
    "              'end_date':      str(ausw_date), \n",
    "              'task_description':   'Together with clinical collaborators from six different hospitals in Spain, Canada and Germany, a public CMR dataset was established from 375 participants, scanned with four different scanners (Siemens, Philips, General Electric (GE) and Canon) and annotated using a consistent contouring SOP across centres. [...] Following the clinical protocol, short-axis views were annotated at the end-diastolic (ED) and end-systolic (ES) phases, as they correspond to the phases used to compute the relevant clinical biomarkers for cardiac diagnosis and follow-up. Three main regions were considered: the left and right ventricle (LV and RV, respectively) cavities and the left ventricle myocardium (MYO). In order to reduce the inter-observer and inter-centre variability in the contours, in particular at the apical and basal regions, a detailed revision of the provided segmentations was performed by four researchers in pairs. They applied the same SOP across all CMR datasets to obtain the final ground truth. To generate consistent annotations for the research community, we chose to apply the SOP that was already used by the ACDC challenge, as follows: a) The LV and RV cavities must be completely covered, including the papillary muscles. b) No interpolation of the MYO boundaries must be performed at the basal region. c) The RV must have a larger surface at the ED time-frame compared to ES. d) The RV does not include the pulmonary artery. Published in: \"Multi-Centre, Multi-Vendor and Multi-Disease Cardiac Segmentation: The M&Ms Challenge\"',\n",
    "              'reader_description': 'Every CMR study was annotated manually by an expert clinician from the centre of origin, with experiences ranging from 3 to more than 10 years.',\n",
    "              'studyuids': studyuids}\n",
    "\n",
    "print(task_env)\n",
    "try: quad.task_coll.insert_one(task_env)\n",
    "except Exception as e: print(e)\n",
    "reader = quad.task_coll.find_one({'_id': task_env['_id']})\n",
    "print(task_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a7c734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e34ecde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "# Insert Annotations\n",
    "folder = os.path.join(store_path, 'Gold')\n",
    "for suid in os.listdir(folder):\n",
    "    annospath = os.path.join(folder, suid)\n",
    "    if not os.path.isdir(annospath): continue\n",
    "    for a_p in os.listdir(annospath):\n",
    "        anno_p = os.path.join(annospath, a_p)\n",
    "        json_anno = json.load(open(anno_p))\n",
    "        json_anno['task_id'] = task_env['_id']\n",
    "        json_anno['studyuid'] = suid\n",
    "        json_anno['sop'] = a_p.replace('.json','')\n",
    "        quad.anno_coll.insert_one(json_anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb0469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
