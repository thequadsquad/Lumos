{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9159f766-9c08-4844-80b5-8bea36ded3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import os\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "from bson.objectid import ObjectId\n",
    "from RoomOfRequirement.Quad import QUAD_Manager\n",
    "from RoomOfRequirement.Evaluation import Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8319e0b-c93c-4b63-96f4-ba21775bd966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quad = QUAD_Manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cc0445d-74e2-474d-b458-ba8451f2032d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nick_Capability_Paper Hadil | Saad | 1988-08-20 | F 363 661f9e0ffa2b5fc9df8d02ad\n",
      "Debugging_Cases Hadil | Saad | 1988-08-20 | F 1 661f9e3ffa2b5fc9df8d02ae\n",
      "HCM             Hadil | Saad | 1988-08-20 | F 39 6620e51a8a6991a2432726b2\n",
      "AS              Hadil | Saad | 1988-08-20 | F 24 6620e5288a6991a2432726b3\n",
      "DCM             Hadil | Saad | 1988-08-20 | F 29 6620e5358a6991a2432726b4\n",
      "WMA             Hadil | Saad | 1988-08-20 | F 40 6620e5428a6991a2432726b5\n",
      "Healthy         Hadil | Saad | 1988-08-20 | F 93 6620e5828a6991a2432726b6\n",
      "Preserved       Hadil | Saad | 1988-08-20 | F 138 6620e5978a6991a2432726b7\n",
      "Diseased        Hadil | Saad | 1988-08-20 | F 132 6620e5bc8a6991a2432726b8\n",
      "\n",
      "Gold ,\t Nr Studyuids:  371 ,\tID:  662106048a6991a24329d568\n",
      "Nick V23H1 ,\t Nr Studyuids:  757 ,\tID:  6626624298d563b4582c1b05\n",
      "AI ,\t Nr Studyuids:  368 ,\tID:  6644b078ebda13c0a882a9fd\n",
      "NI ,\t Nr Studyuids:  370 ,\tID:  6644b38bebda13c0a882a9fe\n",
      "AI_and_NI ,\t Nr Studyuids:  273 ,\tID:  664f1f29b34a4e8065e55356\n"
     ]
    }
   ],
   "source": [
    "# Cohorts\n",
    "cohorts = list(quad.coho_coll.find())\n",
    "for c in cohorts: print(c['name']+' '*(15-len(c['name'])), c['ownername'], len(c['studyuids']), c['_id'])\n",
    "print()\n",
    "\n",
    "# Tasks\n",
    "tasks = list(quad.task_coll.find())\n",
    "for t in tasks: print(t['displayname'], ',\\t Nr Studyuids: ', len(t['studyuids']), ',\\tID: ', t['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a223e0-31af-48b9-935f-c7ebbfafe481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Debugging_Cases\n",
      "\n",
      "HCM\n",
      "..lv_endo\n",
      "dict_keys(['lv_endo', 'lv_epi', 'lv_myo', 'lv_pamu', 'rv_endo'])\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\hadler\\roomofrequirement_06092023_nickpapers\\src\\RoomOfRequirement\\Annotation.py\", line 21, in __init__\n",
      "    try: anno_dict[geom_name]['cont'] = shape(anno_dict[geom_name]['cont'])\n",
      "  File \"D:\\Hadler\\RoR_NickPapers_Env\\lib\\site-packages\\shapely\\geometry\\geo.py\", line 101, in shape\n",
      "    return Polygon(ob[\"coordinates\"][0], ob[\"coordinates\"][1:])\n",
      "  File \"D:\\Hadler\\RoR_NickPapers_Env\\lib\\site-packages\\shapely\\geometry\\polygon.py\", line 230, in __new__\n",
      "    shell = LinearRing(shell)\n",
      "  File \"D:\\Hadler\\RoR_NickPapers_Env\\lib\\site-packages\\shapely\\geometry\\polygon.py\", line 93, in __new__\n",
      "    coordinates = np.array([_coords(o) for o in coordinates])\n",
      "  File \"D:\\Hadler\\RoR_NickPapers_Env\\lib\\site-packages\\shapely\\geometry\\polygon.py\", line 93, in <listcomp>\n",
      "    coordinates = np.array([_coords(o) for o in coordinates])\n",
      "  File \"D:\\Hadler\\RoR_NickPapers_Env\\lib\\site-packages\\shapely\\geometry\\polygon.py\", line 91, in _coords\n",
      "    return [float(c) for c in o]\n",
      "  File \"D:\\Hadler\\RoR_NickPapers_Env\\lib\\site-packages\\shapely\\geometry\\polygon.py\", line 91, in <listcomp>\n",
      "    return [float(c) for c in o]\n",
      "KeyboardInterrupt\n",
      "\n",
      "\n",
      "AS\n",
      "..\n",
      "DCM\n",
      "..\n",
      "WMA\n",
      "."
     ]
    }
   ],
   "source": [
    "task1  = quad.task_coll.find_one({'_id': ObjectId('6644b38bebda13c0a882a9fe')})\n",
    "task2  = quad.task_coll.find_one({'_id': ObjectId('6644b078ebda13c0a882a9fd')})\n",
    "\n",
    "rows = []\n",
    "cols = ['Name', 'Studyuid']\n",
    "for p in ['LVES', 'LVED', 'LVED MYO', 'RVES', 'RVED']: \n",
    "    cols.extend(['Name'] + [name + ' ' + p for name in [task1['displayname'], task2['displayname'], 'Overlooked', 'Oversegmented', 'Different']])\n",
    "\n",
    "for cohort in list(quad.coho_coll.find()):\n",
    "    if cohort['name']=='Nick_Capability_Paper': continue\n",
    "    print()\n",
    "    print(cohort['name'])\n",
    "    for suid_i, suid in enumerate(cohort['studyuids']):\n",
    "        if suid_i%20==1: print('.', end='')\n",
    "        row = []\n",
    "        eval1 = Evaluation(quad, studyuid=suid, task_id=task1['_id'], imagetype='SAX CINE')\n",
    "        eval2 = Evaluation(quad, studyuid=suid, task_id=task2['_id'], imagetype='SAX CINE')\n",
    "\n",
    "        try: row = [eval1.name, eval1.studyuid]\n",
    "        except:\n",
    "            try: row = [eval2.name, eval2.studyuid]\n",
    "            except: continue\n",
    "\n",
    "        cp_name = 'LVESP'\n",
    "        try: row.append(eval1.name)\n",
    "        except: row.append('')\n",
    "        try:\n",
    "            p1     =  eval1.clinical_parameters[cp_name][0]\n",
    "            annos1 = [eval1.get_anno(d, p1) for d in range(eval1.nr_slices)]\n",
    "            conts1 = [a.has_contour('lv_endo') for a in annos1]\n",
    "            row.append(sum(conts1))\n",
    "        except: row.append(np.nan)\n",
    "        try:\n",
    "            p2     =  eval2.clinical_parameters[cp_name][0]\n",
    "            annos2 = [eval2.get_anno(d, p2) for d in range(eval2.nr_slices)]\n",
    "            conts2 = [a.has_contour('lv_endo') for a in annos2]\n",
    "            row.append(sum(conts2))\n",
    "        except: row.append(np.nan)\n",
    "        try:\n",
    "            overlooked    = [c1 and not c2 for c1,c2 in zip(conts1, conts2)]\n",
    "            oversegmented = [not c1 and c2 for c1,c2 in zip(conts1, conts2)]\n",
    "            diff          = [o1 or o2 for o1,o2 in zip(overlooked, oversegmented)]\n",
    "            row.extend([sum(overlooked), sum(oversegmented), sum(diff)])\n",
    "        except Exception as e: row.extend([np.nan, np.nan, np.nan])\n",
    "            \n",
    "        cp_name = 'LVEDP'\n",
    "        try: row.append(eval1.name)\n",
    "        except Exception as e: print(e);row.append('')\n",
    "        try:\n",
    "            p1     =  eval1.clinical_parameters[cp_name][0]\n",
    "            annos1 = [eval1.get_anno(d, p1) for d in range(eval1.nr_slices)]\n",
    "            conts1 = [a.has_contour('lv_endo') for a in annos1]\n",
    "            row.append(sum(conts1))\n",
    "        except: row.append(np.nan)\n",
    "        try:\n",
    "            p2     =  eval2.clinical_parameters[cp_name][0]\n",
    "            annos2 = [eval2.get_anno(d, p2) for d in range(eval2.nr_slices)]\n",
    "            conts2 = [a.has_contour('lv_endo') for a in annos2]\n",
    "            row.append(sum(conts2))\n",
    "        except: row.append(np.nan)\n",
    "        try:\n",
    "            overlooked    = [c1 and not c2 for c1,c2 in zip(conts1, conts2)]\n",
    "            oversegmented = [not c1 and c2 for c1,c2 in zip(conts1, conts2)]\n",
    "            diff          = [o1 or o2 for o1,o2 in zip(overlooked, oversegmented)]\n",
    "            row.extend([sum(overlooked), sum(oversegmented), sum(diff)])\n",
    "        except Exception as e: row.extend([np.nan, np.nan, np.nan])\n",
    "            \n",
    "        cp_name = 'LVEDP'\n",
    "        try: row.append(eval1.name)\n",
    "        except: row.append('')\n",
    "        try:\n",
    "            p1     =  eval1.clinical_parameters[cp_name][0]\n",
    "            annos1 = [eval1.get_anno(d, p1) for d in range(eval1.nr_slices)]\n",
    "            conts1 = [a.has_contour('lv_myo') for a in annos1]\n",
    "            row.append(sum(conts1))\n",
    "        except: row.append(np.nan)\n",
    "        try:\n",
    "            p2     =  eval2.clinical_parameters[cp_name][0]\n",
    "            annos2 = [eval2.get_anno(d, p2) for d in range(eval2.nr_slices)]\n",
    "            conts2 = [a.has_contour('lv_myo') for a in annos2]\n",
    "            row.append(sum(conts2))\n",
    "        except: row.append(np.nan)\n",
    "        try:\n",
    "            overlooked    = [c1 and not c2 for c1,c2 in zip(conts1, conts2)]\n",
    "            oversegmented = [not c1 and c2 for c1,c2 in zip(conts1, conts2)]\n",
    "            diff          = [o1 or o2 for o1,o2 in zip(overlooked, oversegmented)]\n",
    "            row.extend([sum(overlooked), sum(oversegmented), sum(diff)])\n",
    "        except Exception as e: row.extend([np.nan, np.nan, np.nan])\n",
    "            \n",
    "        cp_name = 'RVESP'\n",
    "        try: row.append(eval1.name)\n",
    "        except: row.append('')\n",
    "        try:\n",
    "            p1     =  eval1.clinical_parameters[cp_name][0]\n",
    "            annos1 = [eval1.get_anno(d, p1) for d in range(eval1.nr_slices)]\n",
    "            conts1 = [a.has_contour('rv_endo') for a in annos1]\n",
    "            row.append(sum(conts1))\n",
    "        except: row.append(np.nan)\n",
    "        try:\n",
    "            p2     =  eval2.clinical_parameters[cp_name][0]\n",
    "            annos2 = [eval2.get_anno(d, p2) for d in range(eval2.nr_slices)]\n",
    "            conts2 = [a.has_contour('rv_endo') for a in annos2]\n",
    "            row.append(sum(conts2))\n",
    "        except: row.append(np.nan)\n",
    "        try:\n",
    "            overlooked    = [c1 and not c2 for c1,c2 in zip(conts1, conts2)]\n",
    "            oversegmented = [not c1 and c2 for c1,c2 in zip(conts1, conts2)]\n",
    "            diff          = [o1 or o2 for o1,o2 in zip(overlooked, oversegmented)]\n",
    "            row.extend([sum(overlooked), sum(oversegmented), sum(diff)])\n",
    "        except Exception as e: row.extend([np.nan, np.nan, np.nan])\n",
    "            \n",
    "        cp_name = 'RVEDP'\n",
    "        try: row.append(eval1.name)\n",
    "        except: row.append('')\n",
    "        try:\n",
    "            p1     =  eval1.clinical_parameters[cp_name][0]\n",
    "            annos1 = [eval1.get_anno(d, p1) for d in range(eval1.nr_slices)]\n",
    "            conts1 = [a.has_contour('rv_endo') for a in annos1]\n",
    "            row.append(sum(conts1))\n",
    "        except: row.append(np.nan)\n",
    "        try:\n",
    "            p2     =  eval2.clinical_parameters[cp_name][0]\n",
    "            annos2 = [eval2.get_anno(d, p2) for d in range(eval2.nr_slices)]\n",
    "            conts2 = [a.has_contour('rv_endo') for a in annos2]\n",
    "            row.append(sum(conts2))\n",
    "        except: row.append(np.nan)\n",
    "        try:\n",
    "            overlooked    = [c1 and not c2 for c1,c2 in zip(conts1, conts2)]\n",
    "            oversegmented = [not c1 and c2 for c1,c2 in zip(conts1, conts2)]\n",
    "            diff          = [o1 or o2 for o1,o2 in zip(overlooked, oversegmented)]\n",
    "            row.extend([sum(overlooked), sum(oversegmented), sum(diff)])\n",
    "        except Exception as e: row.extend([np.nan, np.nan, np.nan])\n",
    "\n",
    "        rows.append(row)\n",
    "    \n",
    "    df = DataFrame(rows, columns=cols)\n",
    "    pathname = 'C:/Users/AG-CMR/Desktop/NickPapers_Quad/Debugging_Support/AnnoChoices'\n",
    "    #pathname = '/Users/thomas/Desktop/outputexample'\n",
    "    df.to_excel(os.path.join(pathname, 'Anno_Choices_'+cohort['name']+'_'+task1['displayname']+'_'+task2['displayname']+'.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eedc97-e520-4e58-ac06-814b3d7f1dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RoR_NickPapers_Env",
   "language": "python",
   "name": "ror_nickpapers_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
