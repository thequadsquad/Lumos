{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0c620e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import nibabel as nib\n",
    "from nibabel.testing import data_path\n",
    "import numpy as np\n",
    "\n",
    "import pydicom\n",
    "from pydicom.dataset import Dataset\n",
    "import pydicom._storage_sopclass_uids\n",
    "\n",
    "import rasterio as rio\n",
    "#from rasterio.features import rasterize\n",
    "from rasterio import features\n",
    "\n",
    "from shapely.geometry import Polygon, MultiPolygon, shape, mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5286b0ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from nifti path\n",
    "basepath = ''\n",
    "base_nii = os.path.join(basepath, 'emidec-dataset-1.0.1')\n",
    "\n",
    "# to dicoms and annotation paths\n",
    "imgs_path = os.path.join(basepath, 'Imgs')\n",
    "gold_path = os.path.join(basepath, 'Gold')\n",
    "# to cases\n",
    "#cases_path = os.path.join(basepath, 'Cases')\n",
    "#for p in [imgs_path, gold_path, cases_path]: \n",
    "#    if not os.path.exists(p): os.mkdir(p)\n",
    "\n",
    "# load dictionary of case name --> studyuid and sopinstanceuids of slices\n",
    "with open('case_slice_to_sops.json', 'r') as fp:\n",
    "    sort_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b440ee2-d124-44c5-8183-df21237e893b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_polygon(mask):\n",
    "    \"\"\"Convert mask to Polygons (Origin (0.0, 0.0))\n",
    "    \n",
    "    Note:\n",
    "        rasterio.features.shapes(source, mask=None, connectivity=4, transform=Affine(1.0, 0.0, 0.0, 0.0, 1.0, 0.0))\n",
    "        For Origin (-0.5, -0.5) apply Polygon Transformation -0.5 for all xy\n",
    "        https://rasterio.readthedocs.io/en/latest/api/rasterio.features.html#rasterio.features.shapes\n",
    "        \n",
    "    Args:\n",
    "        mask (ndarray (2D array of np.uint8): binary mask\n",
    "        \n",
    "    Returns:\n",
    "        MultiPolygon | Polygon: Geometries extracted from mask, empty Polygon if empty mask\n",
    "    \"\"\"\n",
    "    polygons = []\n",
    "    for geom, val in rio.features.shapes(mask):\n",
    "        if val:\n",
    "            polygon = shape(geom)\n",
    "            if polygon.geom_type == 'Polygon' and polygon.is_valid: polygons.append(polygon)\n",
    "            else: print('Ignoring GeoJSON with cooresponding shape: ' + \n",
    "                      str(polygon.geom_type) + ' | Valid: ' + str(polygon.is_valid))\n",
    "    return MultiPolygon(polygons) if len(polygons)>0 else Polygon()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "75a0c0ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################\n",
    "# Transform Annos #\n",
    "###################\n",
    "def emidec_to_anno_dict(mask, img_size, pixel_size):\n",
    "    # 1: endo # 2: healthy myo # 3: scar # 4: no reflow\n",
    "    endo_cont     = to_polygon((mask==1).astype(np.int16))\n",
    "    myo_cont      = to_polygon((mask>=2).astype(np.int16))\n",
    "    scar_cont     = to_polygon((mask==3).astype(np.int16))\n",
    "    noreflow_cont = to_polygon((mask==4).astype(np.int16))\n",
    "    anno_dict = dict()\n",
    "    p_size = [float(np.round(pixel_size[0], 6)), float(np.round(pixel_size[1], 6))]\n",
    "    if not endo_cont.is_empty:     anno_dict['lv_endo']  = {'imageSize': img_size, 'pixelSize': p_size, 'cont': mapping(endo_cont)}\n",
    "    if not myo_cont.is_empty :     anno_dict['lv_myo']   = {'imageSize': img_size, 'pixelSize': p_size, 'cont': mapping(myo_cont)}\n",
    "    if not scar_cont.is_empty:     anno_dict['lv_scar']  = {'imageSize': img_size, 'pixelSize': p_size, 'cont': mapping(scar_cont)}\n",
    "    if not noreflow_cont.is_empty: anno_dict['noreflow'] = {'imageSize': img_size, 'pixelSize': p_size, 'cont': mapping(noreflow_cont)}\n",
    "    return anno_dict\n",
    "\n",
    "def emidec_transform_to_readable_annos(nii_annos, bpath, studyiuid, sops):\n",
    "    contdir = os.path.join(bpath, studyiuid) \n",
    "    if not os.path.exists(contdir): os.mkdir(contdir)\n",
    "    h , w, nr_slices = nii_annos.shape\n",
    "    ph, pw, slice_th = nii_annos.header['pixdim'][1:4]\n",
    "    mask_data = nii_annos.get_fdata().astype(np.int32)\n",
    "    ll_annos = []\n",
    "    for d in range(nr_slices):\n",
    "        ll_annos.append(emidec_to_anno_dict(mask_data[:,:,d], [h,w], [ph,pw]))\n",
    "        with open(os.path.join(contdir, sops[d]+'.json'), 'w') as f:\n",
    "            print(ll_annos[-1])\n",
    "            json.dump(ll_annos[-1], f)\n",
    "    return ll_annos        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f88c4c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nifti_to_dcm(nii_imgs, bpath, casename, studyuid, sops):\n",
    "    if not os.path.exists(os.path.join(bpath, casename)):\n",
    "        os.mkdir(os.path.join(bpath, casename))\n",
    "    h, w, nr_slices  = nii_imgs.header['dim'][1:4]\n",
    "    ph, pw, pdepth = nii_imgs.header['pixdim'][1:4]\n",
    "    print(nii_imgs)\n",
    "    imgs = nii_imgs.get_fdata()\n",
    "    ds = Dataset()\n",
    "    ds.SeriesInstanceUID = pydicom.uid.generate_uid()\n",
    "    for d in range(nr_slices):\n",
    "        img = imgs[:,:,d]\n",
    "        img = img.astype(np.uint16)\n",
    "        meta = pydicom.Dataset()\n",
    "        meta.MediaStorageSOPClassUID = pydicom._storage_sopclass_uids.MRImageStorage\n",
    "        meta.MediaStorageSOPInstanceUID = pydicom.uid.generate_uid()\n",
    "        meta.TransferSyntaxUID = pydicom.uid.ExplicitVRLittleEndian\n",
    "        \n",
    "        ds.file_meta = meta\n",
    "        ds.SOPInstanceUID = sops[d]\n",
    "        ds.is_little_endian = True\n",
    "        ds.is_implicit_VR = False\n",
    "        ds.SOPClassUID = pydicom._storage_sopclass_uids.MRImageStorage\n",
    "        ds.PatientName = casename\n",
    "        ds.PatientID = \"123456\"\n",
    "        ds.Modality = \"MR\"\n",
    "        \n",
    "        ds.StudyInstanceUID  = studyuid\n",
    "        ds.FrameOfReferenceUID = pydicom.uid.generate_uid()\n",
    "        ds.SeriesDescription = \"sax lge\"\n",
    "        ds.SliceLocation  = d*pdepth\n",
    "        ds.SliceThickness = str(pdepth)\n",
    "        ds.SpacingBetweenSlices = str(pdepth)\n",
    "        ds.PixelSpacing = str(ph)+'\\\\'+str(pw)\n",
    "        ds.SeriesNumber = 0\n",
    "        ds.BitsStored = 16\n",
    "        ds.BitsAllocated = 16\n",
    "        ds.SamplesPerPixel = 1\n",
    "        ds.HighBit = 15\n",
    "        ds.ImagesInAcquisition = \"1\"\n",
    "        ds.Rows    = h\n",
    "        ds.Columns = w\n",
    "        ds.InstanceNumber = 0\n",
    "        ds.ImagePositionPatient = [0, 0, d*pdepth]\n",
    "        ds.ImageOrientationPatient = [1, 0, 0, 0, 1, 0]\n",
    "        ds.ImageType = r\"ORIGINAL\\PRIMARY\\AXIAL\"\n",
    "        ds.RescaleIntercept = \"0\"\n",
    "        ds.RescaleSlope     = \"1\"\n",
    "        ds.PhotometricInterpretation = \"MONOCHROME2\"\n",
    "        ds.PixelRepresentation = 1\n",
    "        pydicom.dataset.validate_file_meta(ds.file_meta, enforce_standard=True)\n",
    "        ds.PixelData = img.tobytes()\n",
    "        ds.private_block(0x000b, 'Lumos: SAX LGE', create=True)\n",
    "        filename = os.path.join(bpath, casename, str(d)+'.dcm')\n",
    "        ds.save_as(filename=filename, write_like_original=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b05b5e0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "folders = [f for f in os.listdir(base_nii) if os.path.isdir(os.path.join(base_nii, f))]\n",
    "for f in folders:\n",
    "    img_path  = os.path.join(base_nii, f, 'Images')\n",
    "    anno_path = os.path.join(base_nii, f, 'Contours')\n",
    "    nii_imgs  = nib.load(os.path.join(img_path,  f+'.nii.gz'))\n",
    "    nii_annos = nib.load(os.path.join(anno_path, f+'.nii.gz'))\n",
    "    studyiuid, sops = sort_dict[f]['study_uid'], sort_dict[f]['sopinstanceuids']\n",
    "    nifti_to_dcm(nii_imgs, imgs_path, f, studyiuid, sops)\n",
    "    annos = emidec_transform_to_readable_annos(nii_annos, gold_path, studyiuid, sops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fcb9a270",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4071086460.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[183], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    {task_id: ObjectId('66953ff3351f64c12ca179d6')} emidec gold task id\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "{task_id: ObjectId('66953ff3351f64c12ca179d6')} emidec gold task id\n",
    "\n",
    "{name: \"PatientX\"} cases, dicoms, evals, image_orgs\n",
    "{name: \"EMIDEC\"} cohorts\n",
    "\n",
    "{ $and: [ { task_id: ObjectId('65bb92474e35afb663dc6dcd') , studyuid: \"1.2.826.0.1.3680043.8.498.84770591399155535260156713669022621008\" } ] } FWHM, P001\n",
    "\"1.2.826.0.1.3680043.8.498.11307161898731132853843728987059963152\" P002\n",
    "\"1.2.826.0.1.3680043.8.498.89586328180080351709517792489268278244\" P008\n",
    "\"1.2.826.0.1.3680043.8.498.98429712384624343332387349997390016230\" P022\n",
    "\"1.2.826.0.1.3680043.8.498.80940209359570484935093203199410241980\" P028\n",
    "\"1.2.826.0.1.3680043.8.498.10470484482073739411381235242276910676\" P035\n",
    "\"1.2.826.0.1.3680043.8.498.66299984376228452257781909889448293678\" P038\n",
    "\"1.2.826.0.1.3680043.8.498.54081579330563095952156138035623532519\" P043\n",
    "\"1.2.826.0.1.3680043.8.498.10553469388410035014272265768844628497\" P051\n",
    "\"1.2.826.0.1.3680043.8.498.98126826760554798030171018849046942658\" P053\n",
    "\"1.2.826.0.1.3680043.8.498.82112234070847910019345620487810119653\" P055\n",
    "\"1.2.826.0.1.3680043.8.498.12804984749518611674890828147381260355\" P059\n",
    "\"1.2.826.0.1.3680043.8.498.44071527813010678852610504834211799198\" P064\n",
    "\"1.2.826.0.1.3680043.8.498.56304682190392844280230928869543534114\" P071\n",
    "\"1.2.826.0.1.3680043.8.498.10495728983750682277972128398573411394\" P073\n",
    "\"1.2.826.0.1.3680043.8.498.91199922816855767043237018621627511392\" P076\n",
    "\"1.2.826.0.1.3680043.8.498.83935206222398332717932000245464285764\" P080\n",
    "\"1.2.826.0.1.3680043.8.498.88226697983927685486152243677897533684\" P082\n",
    "\"1.2.826.0.1.3680043.8.498.21228448594165958302374490795200104000\" P093\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
